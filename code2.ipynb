{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "# Define data file paths\n",
    "train_file_path = 'C:/Users/DELL/Desktop/IML/Kaggle Competition 1/Data/New Format/train.xlsx'\n",
    "test_file_path = 'C:/Users/DELL/Desktop/IML/Kaggle Competition 1/Data/New Format/test.xlsx'\n",
    "\n",
    "# Function to preprocess data\n",
    "\n",
    "\n",
    "def preprocess_data(data, is_train=True):\n",
    "    # Separate the target variable (hospital_death) from features\n",
    "    if is_train:\n",
    "        X = data.drop(columns=['hospital_death'])\n",
    "        y = data['hospital_death']\n",
    "    else:\n",
    "        X = data.copy()\n",
    "        y = None\n",
    "\n",
    "    # Create a list of numerical and categorical columns\n",
    "    numerical_columns = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_columns = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "    # Create transformers for preprocessing\n",
    "    numerical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse=False))\n",
    "    ])\n",
    "\n",
    "    # Use ColumnTransformer to apply transformations to respective columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_columns),\n",
    "            ('cat', categorical_transformer, categorical_columns)\n",
    "        ])\n",
    "\n",
    "    # Apply preprocessing to the data\n",
    "    X = preprocessor.fit_transform(X)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Read the training and test data\n",
    "train_data = pd.read_excel(train_file_path)\n",
    "test_data = pd.read_excel(test_file_path)\n",
    "\n",
    "# Preprocess the training and test data\n",
    "X_train, y_train = preprocess_data(train_data, is_train=True)\n",
    "X_test, _ = preprocess_data(test_data, is_train=False)\n",
    "\n",
    "# Define XGBoost and CatBoost classifiers with hyperparameter tuning using RandomizedSearchCV\n",
    "xgb_classifier = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "catboost_classifier = CatBoostClassifier(\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# Define hyperparameter grids for tuning (you can adjust these as needed)\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "param_grid_catboost = {\n",
    "    'iterations': [500, 1000],\n",
    "    'depth': [6, 8, 10],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning for each classifier\n",
    "randomized_search_xgb = RandomizedSearchCV(xgb_classifier, param_distributions=param_grid_xgb,\n",
    "                                           cv=5, scoring='roc_auc', n_jobs=-1, n_iter=10, random_state=42)\n",
    "randomized_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "randomized_search_catboost = RandomizedSearchCV(catboost_classifier, param_distributions=param_grid_catboost,\n",
    "                                                cv=5, scoring='roc_auc', n_jobs=-1, n_iter=10, random_state=42)\n",
    "randomized_search_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimators\n",
    "best_xgb_classifier = randomized_search_xgb.best_estimator_\n",
    "best_catboost_classifier = randomized_search_catboost.best_estimator_\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('xgb', best_xgb_classifier),\n",
    "    ('catboost', best_catboost_classifier)\n",
    "], voting='soft')  # Use 'soft' voting for weighted voting based on class probabilities\n",
    "\n",
    "# Fit the VotingClassifier to the training data\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_probabilities = voting_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Create a DataFrame with the test predictions and RecordID\n",
    "test_predictions_df = pd.DataFrame(\n",
    "    {\"RecordID\": test_data[\"RecordID\"], \"hospital_death\": test_probabilities})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "test_predictions_df.to_csv(\"entry 85.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
