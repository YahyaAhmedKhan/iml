{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import time\n",
    "import pa7ndas as pd   \n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def missing_value_counts(dataframe):\n",
    "    missing_counts = dataframe.isnull().sum()\n",
    "    missing_counts_df = pd.DataFrame({'Column': missing_counts.index, 'Missing_Values_Count': missing_counts.values})\n",
    "    return missing_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_impute(df):\n",
    "    # Separate columns into numerical and categorical\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    # Step 1: Impute Numerical Columns with Mean\n",
    "    num_imputer = SimpleImputer(strategy='mean')\n",
    "    df[numerical_columns] = num_imputer.fit_transform(df[numerical_columns])\n",
    "\n",
    "    # Step 2: Impute Categorical Columns with Mode\n",
    "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df[categorical_columns] = cat_imputer.fit_transform(df[categorical_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale_dataframe(df):\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    scaler = MinMaxScaler()\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def convert_numerical_to_categorical(df, num_bins=9):\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Exclude the \"hospital_death\" column from numerical_cols\n",
    "    numerical_cols = [col for col in numerical_cols if col != \"hospital_death\"]\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        bin_labels = [f\"{col}_bin_{i}\" for i in range(num_bins)]\n",
    "        df_copy[col] = pd.cut(df_copy[col], bins=num_bins, labels=bin_labels)\n",
    "\n",
    "    categorical_transformer = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    new_categorical_cols = df_copy.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    combined_categorical = pd.get_dummies(df_copy[new_categorical_cols], drop_first=True)\n",
    "    df_copy.drop(numerical_cols, axis=1, inplace=True)\n",
    "\n",
    "    df_copy = pd.concat([df_copy, combined_categorical], axis=1)\n",
    "\n",
    "    return df_copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "imputed_df = custom_impute(df)\n",
    "imputed_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scale_dataframe(imputed_df)\n",
    "imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_counts(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = convert_numerical_to_categorical(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = pd.get_dummies(cat_df)\n",
    "df_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot.columns\n",
    "pd.DataFrame(df_onehot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_onehot.loc[:, df_onehot.columns != \"hospital_death\"]\n",
    "y = df_onehot[[\"hospital_death\"]]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=6, min_samples_leaf=3, min_samples_split=3)\n",
    "\n",
    "# Fit the model to your data\n",
    "model.fit(X, y)  # Use y if you have a target variable, otherwise omit it\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and their importance scores\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top 20 features\n",
    "selected_features = feature_importance_df['Feature'][:40]\n",
    "\n",
    "# Create a new DataFrame with only the selected features\n",
    "X_selected = X[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=3, min_samples_split=3)\n",
    "\n",
    "model.fit(X, y) \n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "selected_features = feature_importance_df['Feature'][:500]\n",
    "\n",
    "# X = X[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def roc_auc_cv(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    predicted_probabilities = cross_val_score(model, X, y, scoring=\"roc_auc\", cv=cv, n_jobs=-1)\n",
    "\n",
    "    return mean(predicted_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_parameters(X, y):\n",
    "    \n",
    "    param_grid = {\n",
    "        'var_smoothing': [1e-13, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, \n",
    "                          0.09, 0.095, 0.097, 0.099, 0.1, 0.101, 0.103, 0.105, 0.11]\n",
    "    }\n",
    "    \n",
    "\n",
    "    nb = GaussianNB()\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    return best_params, best_score\n",
    "\n",
    "# find_best_parameters(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_best_parameters(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def roc_auc_cv_cnb(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    y_probabilities = cross_val_predict(model, X, y, cv=cv, method='predict_proba', n_jobs=-1)\n",
    "    \n",
    "    # Assuming binary classification, you can select the positive class\n",
    "    # probability (usually class 1)\n",
    "    y_scores = y_probabilities[:, 1]\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y, y_scores)\n",
    "\n",
    "    return roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GaussianNB(var_smoothing=1e-09)\n",
    "model = CategoricalNB()\n",
    "model = DecisionTreeClassifier(max_depth=50, min_samples_leaf=400, min_samples_split=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_cv(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = X_test[selected_features]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_probs = model.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "md_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_model(model, test_file, output_file):\n",
    "    \n",
    "    df_test = pd.read_csv(test_file)\n",
    "    record_ids = df_test[\"RecordID\"]\n",
    "    \n",
    "    df_test_imputed = custom_impute(df_test)\n",
    "    cat_df = convert_numerical_to_categorical(df_test_imputed)\n",
    "    df_test_onehot = pd.get_dummies(cat_df)\n",
    "    \n",
    "    # df_test_onehot = pd.get_dummies(df_test_imputed)\n",
    "    # min_max_scale_dataframe(df_test_onehot)\n",
    "    \n",
    "    X_test = df_test_onehot.loc[:, df_test_onehot.columns != \"hospital_death\"]\n",
    "    # X_test = X_test[selected_features]\n",
    "    # Generate predictions using the model\n",
    "    probs = model.predict_proba(X_test)\n",
    "    probs = probs[:, 1]\n",
    "    \n",
    "    # Create a DataFrame for the results\n",
    "    result = pd.DataFrame({'RecordID': record_ids, 'hospital_death': probs})\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    result.to_csv(output_file, index=False, header=[\"RecordID\", \"hospital_death\"])\n",
    "    \n",
    "generate_predictions_for_model(model, \"test.csv\", \"results33.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
