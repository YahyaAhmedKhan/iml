{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import time\n",
    "import pandas as pd   \n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scale(df):\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    scaler = RobustScaler()\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "def knn_impute_numerical_columns(df, n_neighbors=100):\n",
    "    df_imputed = df.copy()\n",
    "    df_imputed = pd.get_dummies(drop_first=False, data=df_imputed)\n",
    "    \n",
    "    categorical_columns = df_imputed.select_dtypes(exclude=['number']).columns\n",
    "    numerical_cols = df_imputed.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    # imputer = SimpleImputer(strategy='mean') \n",
    "    df_imputed[numerical_cols] = imputer.fit_transform(df_imputed[numerical_cols])\n",
    "    \n",
    "    # Label encode categorical columns\n",
    "    # label_encoders = {}\n",
    "    # for col in categorical_columns:\n",
    "    #     label_encoders[col] = LabelEncoder()\n",
    "    #     df_imputed[col] = label_encoders[col].fit_transform(df_imputed[col])\n",
    "\n",
    "    # imputer = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "\n",
    "    \n",
    "    # df_imputed[categorical_columns] = imputer.fit_transform(df_imputed[categorical_columns])\n",
    "    # cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    # df_imputed[categorical_columns] = cat_imputer.fit_transform(df_imputed[categorical_columns])\n",
    "\n",
    "    return df_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/imlenv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['hospital_death'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/yahyaahmedkhan/Desktop/dev/UniProjects/iml-challenge/phase2.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yahyaahmedkhan/Desktop/dev/UniProjects/iml-challenge/phase2.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m numerical_cols \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mnumber\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yahyaahmedkhan/Desktop/dev/UniProjects/iml-challenge/phase2.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yahyaahmedkhan/Desktop/dev/UniProjects/iml-challenge/phase2.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m X_train_num_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(X_train[numerical_cols])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yahyaahmedkhan/Desktop/dev/UniProjects/iml-challenge/phase2.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m X_test_num_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test[numerical_cols])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yahyaahmedkhan/Desktop/dev/UniProjects/iml-challenge/phase2.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Combine encoded categorical and scaled numerical features\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/imlenv/lib/python3.10/site-packages/pandas/core/frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3900\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3901\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3902\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3904\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/imlenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6116\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6118\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/imlenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6177\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6178\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['hospital_death'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Load your dataset into a DataFrame (assuming it's named 'df')\n",
    "# Perform data preprocessing here\n",
    "\n",
    "# Split the dataset into features (X) and the target variable (y)\n",
    "X = df.loc[:, df.columns != \"hospital_death\"]\n",
    "y = df[[\"hospital_death\"]]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess categorical columns (one-hot encoding)\n",
    "categorical_cols = df.select_dtypes(exclude=['number']).columns\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_test_cat_encoded = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# Preprocess numerical columns (standard scaling)\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test_num_scaled = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# Combine encoded categorical and scaled numerical features\n",
    "X_train_processed = pd.concat([pd.DataFrame(X_train_cat_encoded), pd.DataFrame(X_train_num_scaled)], axis=1)\n",
    "X_test_processed = pd.concat([pd.DataFrame(X_test_cat_encoded), pd.DataFrame(X_test_num_scaled)], axis=1)\n",
    "\n",
    "# Build and train an MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', max_iter=100, random_state=42)\n",
    "mlp_classifier.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = mlp_classifier.predict(X_test_processed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, mlp_classifier.predict_proba(X_test_processed)[:, 1])\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
