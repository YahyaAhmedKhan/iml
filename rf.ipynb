{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import time\n",
    "import pandas as pd   \n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scale(df):\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    scaler = RobustScaler()\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "def knn_impute_numerical_columns(df, n_neighbors=10):\n",
    "    df_imputed = df.copy()\n",
    "    # df_imputed = pd.get_dummies(drop_first=True, data=df_imputed)\n",
    "    \n",
    "    categorical_columns = df_imputed.select_dtypes(exclude=['number']).columns\n",
    "    numerical_cols = df_imputed.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    # imputer = SimpleImputer(strategy='mean') \n",
    "    df_imputed[numerical_cols] = imputer.fit_transform(df_imputed[numerical_cols])\n",
    "    \n",
    "    # Label encode categorical columns\n",
    "    # label_encoders = {}\n",
    "    # for col in categorical_columns:\n",
    "    #     label_encoders[col] = LabelEncoder()\n",
    "    #     df_imputed[col] = label_encoders[col].fit_transform(df_imputed[col])\n",
    "\n",
    "    # imputer = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df_imputed[categorical_columns] = imputer.fit_transform(df_imputed[categorical_columns])\n",
    "    \n",
    "    # cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    # df_imputed[categorical_columns] = cat_imputer.fit_transform(df_imputed[categorical_columns])\n",
    "\n",
    "    return df_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>icu_admit_source</th>\n",
       "      <th>icu_stay_type</th>\n",
       "      <th>icu_type</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "      <th>...</th>\n",
       "      <th>h1_sysbp_min</th>\n",
       "      <th>h1_sysbp_noninvasive_max</th>\n",
       "      <th>h1_sysbp_noninvasive_min</th>\n",
       "      <th>d1_glucose_max</th>\n",
       "      <th>d1_potassium_max</th>\n",
       "      <th>apache_4a_hospital_death_prob</th>\n",
       "      <th>apache_4a_icu_death_prob</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1.241270</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Floor</td>\n",
       "      <td>transfer</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.805556</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.805556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.99996</td>\n",
       "      <td>-0.789474</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>African American</td>\n",
       "      <td>M</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.945946</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>2.164706</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.99992</td>\n",
       "      <td>-0.429825</td>\n",
       "      <td>-0.073016</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Floor</td>\n",
       "      <td>admit</td>\n",
       "      <td>MICU</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>...</td>\n",
       "      <td>1.305556</td>\n",
       "      <td>1.189189</td>\n",
       "      <td>1.305556</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.125</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.99988</td>\n",
       "      <td>-0.815789</td>\n",
       "      <td>0.860317</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Neurological</td>\n",
       "      <td>Neurologic</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>1.282353</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.99984</td>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>CSICU</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.297297</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.458824</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.99984</td>\n",
       "      <td>-0.807018</td>\n",
       "      <td>0.473016</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Musculoskeletal/Skin</td>\n",
       "      <td>Undefined Diagnoses</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472222</td>\n",
       "      <td>-0.864865</td>\n",
       "      <td>-0.472222</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.99988</td>\n",
       "      <td>-0.412281</td>\n",
       "      <td>0.568254</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>Floor</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Neurological</td>\n",
       "      <td>Neurologic</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-0.047059</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.99992</td>\n",
       "      <td>-0.956140</td>\n",
       "      <td>1.180952</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>transfer</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.405405</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.376471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.99996</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Operating Room / Recovery</td>\n",
       "      <td>admit</td>\n",
       "      <td>Cardiac ICU</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>-0.352941</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.453968</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>-0.176471</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RecordID  hospital_id    icu_id         ethnicity gender  \\\n",
       "0      -1.00000    -0.666667  1.241270         Caucasian      M   \n",
       "1      -0.99996    -0.789474  0.012698  African American      M   \n",
       "2      -0.99992    -0.429825 -0.073016         Caucasian      M   \n",
       "3      -0.99988    -0.815789  0.860317         Caucasian      M   \n",
       "4      -0.99984     0.745614  0.968254         Caucasian      F   \n",
       "...         ...          ...       ...               ...    ...   \n",
       "49995   0.99984    -0.807018  0.473016         Caucasian      M   \n",
       "49996   0.99988    -0.412281  0.568254         Caucasian      F   \n",
       "49997   0.99992    -0.956140  1.180952         Caucasian      F   \n",
       "49998   0.99996     0.245614  0.571429         Caucasian      M   \n",
       "49999   1.00000     0.710526  0.453968         Caucasian      M   \n",
       "\n",
       "                icu_admit_source icu_stay_type      icu_type  \\\n",
       "0                          Floor      transfer  Med-Surg ICU   \n",
       "1           Accident & Emergency         admit  Med-Surg ICU   \n",
       "2                          Floor         admit          MICU   \n",
       "3           Accident & Emergency         admit  Med-Surg ICU   \n",
       "4           Accident & Emergency         admit         CSICU   \n",
       "...                          ...           ...           ...   \n",
       "49995       Accident & Emergency         admit  Med-Surg ICU   \n",
       "49996                      Floor         admit  Med-Surg ICU   \n",
       "49997       Accident & Emergency      transfer  Med-Surg ICU   \n",
       "49998  Operating Room / Recovery         admit   Cardiac ICU   \n",
       "49999       Accident & Emergency         admit  Med-Surg ICU   \n",
       "\n",
       "       apache_3j_bodysystem  apache_2_bodysystem  ...  h1_sysbp_min  \\\n",
       "0                 Metabolic            Metabolic  ...     -0.805556   \n",
       "1            Cardiovascular       Cardiovascular  ...     -0.555556   \n",
       "2               Respiratory          Respiratory  ...      1.305556   \n",
       "3              Neurological           Neurologic  ...      0.694444   \n",
       "4            Cardiovascular       Cardiovascular  ...      0.111111   \n",
       "...                     ...                  ...  ...           ...   \n",
       "49995  Musculoskeletal/Skin  Undefined Diagnoses  ...     -0.472222   \n",
       "49996          Neurological           Neurologic  ...      0.833333   \n",
       "49997                Sepsis       Cardiovascular  ...     -0.833333   \n",
       "49998        Cardiovascular       Cardiovascular  ...      0.611111   \n",
       "49999           Respiratory          Respiratory  ...      0.277778   \n",
       "\n",
       "       h1_sysbp_noninvasive_max  h1_sysbp_noninvasive_min  d1_glucose_max  \\\n",
       "0                     -1.000000                 -0.805556             NaN   \n",
       "1                     -0.945946                 -0.555556        2.164706   \n",
       "2                      1.189189                  1.305556        0.129412   \n",
       "3                      0.891892                  0.694444        1.282353   \n",
       "4                     -0.297297                  0.111111       -0.458824   \n",
       "...                         ...                       ...             ...   \n",
       "49995                 -0.864865                 -0.472222       -0.600000   \n",
       "49996                  0.405405                  0.833333       -0.047059   \n",
       "49997                 -0.405405                 -0.833333       -0.376471   \n",
       "49998                  0.189189                  0.611111       -0.352941   \n",
       "49999                  0.432432                  0.277778       -0.176471   \n",
       "\n",
       "       d1_potassium_max  apache_4a_hospital_death_prob  \\\n",
       "0                   NaN                      -0.333333   \n",
       "1                -0.500                            NaN   \n",
       "2                 0.125                       2.750000   \n",
       "3                -0.375                       0.583333   \n",
       "4                -0.250                       0.833333   \n",
       "...                 ...                            ...   \n",
       "49995            -0.250                      -0.250000   \n",
       "49996            -0.375                      -0.250000   \n",
       "49997               NaN                       0.333333   \n",
       "49998            -0.125                      -0.416667   \n",
       "49999             1.000                       0.000000   \n",
       "\n",
       "       apache_4a_icu_death_prob  immunosuppression  \\\n",
       "0                     -0.333333                0.0   \n",
       "1                           NaN                0.0   \n",
       "2                      2.166667                0.0   \n",
       "3                      0.666667                0.0   \n",
       "4                      0.833333                0.0   \n",
       "...                         ...                ...   \n",
       "49995                 -0.166667                0.0   \n",
       "49996                 -0.333333                0.0   \n",
       "49997                  0.500000                1.0   \n",
       "49998                 -0.333333                0.0   \n",
       "49999                  0.000000                0.0   \n",
       "\n",
       "       solid_tumor_with_metastasis  hospital_death  \n",
       "0                              0.0             0.0  \n",
       "1                              0.0             0.0  \n",
       "2                              0.0             0.0  \n",
       "3                              0.0             0.0  \n",
       "4                              0.0             0.0  \n",
       "...                            ...             ...  \n",
       "49995                          0.0             0.0  \n",
       "49996                          0.0             0.0  \n",
       "49997                          0.0             0.0  \n",
       "49998                          0.0             0.0  \n",
       "49999                          0.0             0.0  \n",
       "\n",
       "[50000 rows x 58 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robust_scale(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = knn_impute_numerical_columns(df, n_neighbors=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 58)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped = df_imputed.copy().dropna(axis=0)\n",
    "df_dropped.shape\n",
    "# missing_value_counts(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 96)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot = pd.get_dummies(df_dropped)\n",
    "df_onehot\n",
    "df_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 95)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_onehot.loc[:, df_onehot.columns != \"hospital_death\"]\n",
    "y = df_onehot[[\"hospital_death\"]]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/imlenv/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46                 apache_4a_hospital_death_prob\n",
       "47                      apache_4a_icu_death_prob\n",
       "10                              gcs_motor_apache\n",
       "24                                   d1_spo2_min\n",
       "25                                  d1_sysbp_min\n",
       "9                                gcs_eyes_apache\n",
       "26                      d1_sysbp_noninvasive_min\n",
       "7                            apache_3j_diagnosis\n",
       "17                             ventilated_apache\n",
       "16                                   temp_apache\n",
       "12                             gcs_verbal_apache\n",
       "27                                   d1_temp_min\n",
       "22                        d1_mbp_noninvasive_min\n",
       "21                                    d1_mbp_min\n",
       "18                                 d1_diasbp_min\n",
       "6                             apache_2_diagnosis\n",
       "19                     d1_diasbp_noninvasive_min\n",
       "20                              d1_heartrate_max\n",
       "13                             heart_rate_apache\n",
       "23                               d1_resprate_max\n",
       "14                              intubated_apache\n",
       "37                               h1_resprate_min\n",
       "3                                            age\n",
       "43                      h1_sysbp_noninvasive_min\n",
       "41                                  h1_sysbp_min\n",
       "36                               h1_resprate_max\n",
       "35                        h1_mbp_noninvasive_min\n",
       "33                                    h1_mbp_min\n",
       "15                               resprate_apache\n",
       "5                               pre_icu_los_days\n",
       "44                                d1_glucose_max\n",
       "39                                   h1_spo2_min\n",
       "45                              d1_potassium_max\n",
       "29                     h1_diasbp_noninvasive_min\n",
       "28                                 h1_diasbp_min\n",
       "30                              h1_heartrate_max\n",
       "31                              h1_heartrate_min\n",
       "2                                         icu_id\n",
       "38                                   h1_spo2_max\n",
       "40                                  h1_sysbp_max\n",
       "42                      h1_sysbp_noninvasive_max\n",
       "34                        h1_mbp_noninvasive_max\n",
       "0                                       RecordID\n",
       "32                                    h1_mbp_max\n",
       "1                                    hospital_id\n",
       "4                               elective_surgery\n",
       "85            apache_2_bodysystem_Cardiovascular\n",
       "88                 apache_2_bodysystem_Metabolic\n",
       "60    icu_admit_source_Operating Room / Recovery\n",
       "83                   apache_3j_bodysystem_Sepsis\n",
       "Name: Feature, dtype: object"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=1000, max_depth=7, random_state=0, n_jobs=3)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = estimator.feature_importances_\n",
    "\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_num = 50\n",
    "selected_features = feature_importance_df['Feature'][:feature_num]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_cv(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "    predicted_probabilities = cross_val_score(model, X, y, scoring=\"roc_auc\", cv=cv, n_jobs=-1, verbose=2)\n",
    "\n",
    "    return mean(predicted_probabilities)\n",
    "def calculate_roc_auc(model, X_test, y_test):\n",
    "    md_probs = model.predict_proba(X_test)\n",
    "    md_probs = md_probs[:, 1]\n",
    "    md_auc = roc_auc_score(y_test, md_probs)\n",
    "    return md_auc\n",
    "\n",
    "# roc_auc = calculate_roc_auc(model, X_test, y_test)\n",
    "# print(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_classifier = DecisionTreeClassifier(max_depth=7, min_samples_leaf=50, min_samples_split=50)\n",
    "model = AdaBoostClassifier(base_classifier, n_estimators=100, random_state=42)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "roc_auc_cv(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classifier = KNeighborsClassifier(n_neighbors=300)\n",
    "model = BaggingClassifier(base_classifier, n_estimators=200, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "calculate_roc_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=300, learning_rate=0.3, max_depth=1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "calculate_roc_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=200, learning_rate=0.3, max_depth=1, random_state=42)\n",
    "\n",
    "# Define the parameter grid you want to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # You can adjust these values\n",
    "    'learning_rate': [0.1, 0.2, 0.3],  # You can adjust these values\n",
    "    'max_depth': [1, 2, 3],  # You can adjust these values\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=3)\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catboost = pd.read_csv('train.csv')\n",
    "df_catboost = pd.get_dummies(df_catboost)\n",
    "X = df_catboost.loc[:, df_catboost.columns != \"hospital_death\"]\n",
    "y = df_catboost[[\"hospital_death\"]]\n",
    "# X = X[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 95)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 5.86ms\tremaining: 3.45s\n",
      "20:\ttotal: 138ms\tremaining: 3.75s\n",
      "40:\ttotal: 281ms\tremaining: 3.77s\n",
      "60:\ttotal: 423ms\tremaining: 3.67s\n",
      "80:\ttotal: 559ms\tremaining: 3.51s\n",
      "100:\ttotal: 692ms\tremaining: 3.35s\n",
      "120:\ttotal: 816ms\tremaining: 3.16s\n",
      "140:\ttotal: 942ms\tremaining: 3s\n",
      "160:\ttotal: 1.07s\tremaining: 2.85s\n",
      "180:\ttotal: 1.19s\tremaining: 2.69s\n",
      "200:\ttotal: 1.32s\tremaining: 2.55s\n",
      "220:\ttotal: 1.44s\tremaining: 2.4s\n",
      "240:\ttotal: 1.57s\tremaining: 2.27s\n",
      "260:\ttotal: 1.7s\tremaining: 2.14s\n",
      "280:\ttotal: 1.82s\tremaining: 2s\n",
      "300:\ttotal: 1.95s\tremaining: 1.87s\n",
      "320:\ttotal: 2.12s\tremaining: 1.77s\n",
      "340:\ttotal: 2.25s\tremaining: 1.64s\n",
      "360:\ttotal: 2.38s\tremaining: 1.51s\n",
      "380:\ttotal: 2.5s\tremaining: 1.37s\n",
      "400:\ttotal: 2.62s\tremaining: 1.23s\n",
      "420:\ttotal: 2.74s\tremaining: 1.1s\n",
      "440:\ttotal: 2.87s\tremaining: 968ms\n",
      "460:\ttotal: 2.99s\tremaining: 837ms\n",
      "480:\ttotal: 3.11s\tremaining: 706ms\n",
      "500:\ttotal: 3.24s\tremaining: 575ms\n",
      "520:\ttotal: 3.36s\tremaining: 445ms\n",
      "540:\ttotal: 3.48s\tremaining: 316ms\n",
      "560:\ttotal: 3.61s\tremaining: 187ms\n",
      "580:\ttotal: 3.74s\tremaining: 57.9ms\n",
      "589:\ttotal: 3.79s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8861038996435868"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=590,\n",
    "    depth=5,\n",
    "    learning_rate=0.09,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_seed=69,\n",
    "    verbose=20,\n",
    "    l2_leaf_reg=2,\n",
    "    border_count=80,\n",
    "    leaf_estimation_iterations=10,\n",
    "    # subsample=0.8,\n",
    "    # min_data_in_leaf=3,\n",
    "    # colsample_bylevel=0.8,\n",
    "    \n",
    ")\n",
    "# roc_auc_cv(model, X, y)\n",
    "model.fit(X_train, y_train)\n",
    "calculate_roc_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'iterations': [375],\n",
    "    'depth': [5],\n",
    "    'learning_rate': [ 0.09 ],\n",
    "    'l2_leaf_reg': [1, 2, 3],\n",
    "    'border_count': [60, 70, 50],  \n",
    "    'leaf_estimation_iterations': [20, 30, 10],\n",
    "    \n",
    "}\n",
    "\n",
    "# Create the CatBoostClassifier\n",
    "model = CatBoostClassifier(loss_function='Logloss', eval_metric='AUC', random_seed=42, verbose=20)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_jobs=3)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best AUC Score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the XGBoost classifier with default parameters\n",
    "model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [800, 900, 700],\n",
    "    # 'max_depth': [4, 5],\n",
    "    'learning_rate': [0.038, 0.039, 0.037],\n",
    "    # 'min_child_weight': [1, 2],\n",
    "    'colsample_bytree': [0.8, 0.83, 0.77],\n",
    "    # 'alpha': [0.1],\n",
    "    # 'eval_metric': ['logloss'],\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=2)\n",
    "\n",
    "# Fit the grid search to your data (X, y)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the corresponding ROC AUC score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best ROC AUC Score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != \"hospital_death\"]\n",
    "y = df[[\"hospital_death\"]]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=800,  \n",
    "    max_depth=4,\n",
    "    learning_rate=0.038,\n",
    "    random_state=49,\n",
    "    min_child_weight=1,\n",
    "    colsample_bytree=0.78,\n",
    "    alpha= 0.1,\n",
    "    eval_metric='logloss',\n",
    ")\n",
    "# roc_auc_cv(model, X, y)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "roc_auc_cv(model, X, y)\n",
    "# calculate_roc_auc(model, X_test, y_test)\n",
    "# print(roc)\n",
    "# model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64,32, 16), \n",
    "    activation='relu', \n",
    "    max_iter=10, \n",
    "    random_state=42, \n",
    "    solver='adam',  # You can adjust other hyperparameters as needed\n",
    "    learning_rate_init=0.001,\n",
    "    shuffle=True,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=300)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_cv(model, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(n_estimators=100, max_depth=17, min_samples_leaf=100, min_samples_split=200, random_state=0, n_jobs=3)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_cv(model, X, y)\n",
    "# calculate_roc_auc(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(n_estimators=100, max_depth=17, min_samples_leaf=100, min_samples_split=200, random_state=0, n_jobs=3)\n",
    "model.fit(X_train, y_train)\n",
    "# roc_auc_cv(model, X, y)\n",
    "calculate_roc_auc(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catboost = pd.read_csv('train.csv')\n",
    "robust_scale(df_catboost)\n",
    "df_catboost = knn_impute_numerical_columns(df_catboost, n_neighbors=10)\n",
    "df_catboost = pd.get_dummies(df_catboost)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 95)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df_catboost.loc[:, df_catboost.columns != \"hospital_death\"]\n",
    "y = df_catboost[[\"hospital_death\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 7.3ms\tremaining: 4.3s\n",
      "20:\ttotal: 191ms\tremaining: 5.18s\n",
      "40:\ttotal: 436ms\tremaining: 5.84s\n",
      "60:\ttotal: 633ms\tremaining: 5.49s\n",
      "80:\ttotal: 839ms\tremaining: 5.27s\n",
      "100:\ttotal: 1.03s\tremaining: 4.98s\n",
      "120:\ttotal: 1.23s\tremaining: 4.77s\n",
      "140:\ttotal: 1.42s\tremaining: 4.52s\n",
      "160:\ttotal: 1.6s\tremaining: 4.28s\n",
      "180:\ttotal: 1.79s\tremaining: 4.04s\n",
      "200:\ttotal: 1.98s\tremaining: 3.84s\n",
      "220:\ttotal: 2.23s\tremaining: 3.73s\n",
      "240:\ttotal: 2.42s\tremaining: 3.51s\n",
      "260:\ttotal: 2.61s\tremaining: 3.29s\n",
      "280:\ttotal: 2.79s\tremaining: 3.07s\n",
      "300:\ttotal: 2.98s\tremaining: 2.86s\n",
      "320:\ttotal: 3.17s\tremaining: 2.65s\n",
      "340:\ttotal: 3.35s\tremaining: 2.45s\n",
      "360:\ttotal: 3.54s\tremaining: 2.24s\n",
      "380:\ttotal: 3.73s\tremaining: 2.05s\n",
      "400:\ttotal: 3.92s\tremaining: 1.85s\n",
      "420:\ttotal: 4.12s\tremaining: 1.66s\n",
      "440:\ttotal: 4.36s\tremaining: 1.47s\n",
      "460:\ttotal: 4.55s\tremaining: 1.27s\n",
      "480:\ttotal: 4.73s\tremaining: 1.07s\n",
      "500:\ttotal: 4.91s\tremaining: 873ms\n",
      "520:\ttotal: 5.1s\tremaining: 675ms\n",
      "540:\ttotal: 5.28s\tremaining: 478ms\n",
      "560:\ttotal: 5.47s\tremaining: 283ms\n",
      "580:\ttotal: 5.65s\tremaining: 87.6ms\n",
      "589:\ttotal: 5.74s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8856506985810823"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=590,\n",
    "    depth=5,\n",
    "    learning_rate=0.09,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_seed=69,\n",
    "    verbose=20,\n",
    "    l2_leaf_reg=2,\n",
    "    border_count=80,\n",
    "    leaf_estimation_iterations=20,\n",
    "    # scale_pos_weight=0.4,\n",
    "    # subsample=0.8,\n",
    "    # min_data_in_leaf=1,\n",
    "    # colsample_bylevel=0.8,\n",
    "    \n",
    ")\n",
    "# roc_auc_cv(model, X, y)\n",
    "model.fit(X_train, y_train)\n",
    "calculate_roc_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 8.73ms\tremaining: 5.14s\n",
      "20:\ttotal: 221ms\tremaining: 6s\n",
      "40:\ttotal: 456ms\tremaining: 6.11s\n",
      "60:\ttotal: 679ms\tremaining: 5.89s\n",
      "80:\ttotal: 889ms\tremaining: 5.58s\n",
      "100:\ttotal: 1.16s\tremaining: 5.6s\n",
      "120:\ttotal: 1.4s\tremaining: 5.41s\n",
      "140:\ttotal: 1.64s\tremaining: 5.22s\n",
      "160:\ttotal: 1.86s\tremaining: 4.96s\n",
      "180:\ttotal: 2.12s\tremaining: 4.78s\n",
      "200:\ttotal: 2.32s\tremaining: 4.5s\n",
      "220:\ttotal: 2.53s\tremaining: 4.22s\n",
      "240:\ttotal: 2.76s\tremaining: 4s\n",
      "260:\ttotal: 2.97s\tremaining: 3.74s\n",
      "280:\ttotal: 3.17s\tremaining: 3.48s\n",
      "300:\ttotal: 3.39s\tremaining: 3.25s\n",
      "320:\ttotal: 3.6s\tremaining: 3.02s\n",
      "340:\ttotal: 3.8s\tremaining: 2.78s\n",
      "360:\ttotal: 4s\tremaining: 2.54s\n",
      "380:\ttotal: 4.21s\tremaining: 2.31s\n",
      "400:\ttotal: 4.43s\tremaining: 2.09s\n",
      "420:\ttotal: 4.67s\tremaining: 1.87s\n",
      "440:\ttotal: 4.92s\tremaining: 1.66s\n",
      "460:\ttotal: 5.12s\tremaining: 1.43s\n",
      "480:\ttotal: 5.33s\tremaining: 1.21s\n",
      "500:\ttotal: 5.53s\tremaining: 983ms\n",
      "520:\ttotal: 5.76s\tremaining: 764ms\n",
      "540:\ttotal: 5.97s\tremaining: 541ms\n",
      "560:\ttotal: 6.18s\tremaining: 319ms\n",
      "580:\ttotal: 6.39s\tremaining: 99ms\n",
      "589:\ttotal: 6.49s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x10e1a0eb0>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_model(model, test_file, output_file):\n",
    "    \n",
    "    df = pd.read_csv(test_file)\n",
    "    record_ids = df[\"RecordID\"]\n",
    "    \n",
    "    # robust_scale(df)\n",
    "    # df = knn_impute_numerical_columns(df, n_neighbors=10)\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    # X_test = df[selected_features] \n",
    "    \n",
    "    X_test = df.loc[:, df.columns != \"hospital_death\"]\n",
    "    \n",
    "    probs = model.predict_proba(X_test)\n",
    "    probs = probs[:, 1]\n",
    "    \n",
    "    # Create a DataFrame for the results\n",
    "    result = pd.DataFrame({'RecordID': record_ids, 'hospital_death': probs})\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    result.to_csv(output_file, index=False, header=[\"RecordID\", \"hospital_death\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions_for_model(model, \"test.csv\", \"results74.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3439, number of negative: 36561\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4884\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 86\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.085975 -> initscore=-2.363801\n",
      "[LightGBM] [Info] Start training from score -2.363801\n",
      "ROC AUC: 0.8866037897044403\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  \n",
    "    'metric': 'binary_logloss', \n",
    "    'boosting_type': 'gbdt',  \n",
    "    'num_leaves': 31,  \n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,  \n",
    "    'bagging_fraction': 0.90,  \n",
    "    'bagging_freq': 5,  # \n",
    "    'verbose': 1,\n",
    "    'max_bin': 255,\n",
    "    'min_data_in_leaf': 40,  # Example value, adjust as needed\n",
    "    'min_sum_hessian_in_leaf': 1e-4  ,# Example value, adjust as needed\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "num_round = 211# Number of boosting iterations\n",
    "lightgbm_model = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "\n",
    "y_pred_prob = lightgbm_model.predict(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "# roc_auc_cv(lightgbm_model, X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',  # Binary classification\n",
    "    'metric': 'binary_logloss',  # Logarithmic loss for binary classification\n",
    "    'boosting_type': 'gbdt',  # Gradient boosting decision tree\n",
    "    'num_leaves': 31,  # Maximum number of leaves in each tree\n",
    "    'learning_rate': 0.05,  # Step size shrinkage\n",
    "    'feature_fraction': 0.75,  # Fraction of features to be used in each iteration\n",
    "    'bagging_fraction': 0.90,  # Fraction of data to be randomly sampled for training\n",
    "    'bagging_freq': 5,  # Frequency for bagging\n",
    "    'verbose': 0  # Verbosity level,    \n",
    "}\n",
    "\n",
    "num_round = 210  # Number of boosting iterations\n",
    "lightgbm_model = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "\n",
    "y_pred_prob = lightgbm_model.predict(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_resultfile_lbgm(model, test_file, output_file):\n",
    "    \n",
    "    df_test = pd.read_csv(test_file)\n",
    "    record_ids = df_test[\"RecordID\"]\n",
    "    \n",
    "    df_scaled = robust_scale(df_test)\n",
    "    df_test_imputed = knn_impute_numerical_columns(df_scaled, n_neighbors=100)\n",
    "    df_test_onehot = pd.get_dummies(df_test_imputed)\n",
    "    \n",
    "    X_test = df_test_onehot[selected_features] \n",
    "    \n",
    "    # X_test = df_test_onehot.loc[:, df_test_onehot.columns != \"hospital_death\"]\n",
    "    \n",
    "    probs = model.predict(X_test)\n",
    "    \n",
    "    # Create a DataFrame for the results\n",
    "    result = pd.DataFrame({'RecordID': record_ids, 'hospital_death': probs})\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    result.to_csv(output_file, index=False, header=[\"RecordID\", \"hospital_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_resultfile_lbgm(lightgbm_model, \"test.csv\", \"results54.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',  # Binary classification\n",
    "    'metric': 'binary_logloss',  # Logarithmic loss for binary classification\n",
    "    'boosting_type': 'gbdt',  # Gradient boosting decision tree\n",
    "    'num_leaves': 31,  # Maximum number of leaves in each tree\n",
    "    'learning_rate': 0.05,  # Step size shrinkage\n",
    "    'feature_fraction': 0.75,  # Fraction of features to be used in each iteration\n",
    "    'bagging_fraction': 0.90,  # Fraction of data to be randomly sampled for training\n",
    "    'bagging_freq': 5,  # Frequency for bagging\n",
    "    'verbose': 0  # Verbosity level,    \n",
    "}\n",
    "\n",
    "num_round = 210  # Number of boosting iterations\n",
    "lightgbm_model = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "\n",
    "y_pred_prob = lightgbm_model.predict(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions using the trained model\n",
    "record_ids = X[\"RecordID\"]\n",
    "probs = model.predict(X_test)\n",
    "\n",
    "result = pd.DataFrame({'RecordID': record_ids, 'hospital_death': probs})\n",
    "    \n",
    "# Save the results to a CSV file\n",
    "result.to_csv(\"results54\", index=False, header=[\"RecordID\", \"hospital_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lightgbm_model.predict(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')  # Replace with your training dataset path\n",
    "test_data = pd.read_csv('test.csv')    # Replace with your other dataset path\n",
    "\n",
    "\n",
    "# Create a LightGBM dataset from the training data\n",
    "train_dataset = lgb.Dataset(X, label=y)\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',  # Binary classification\n",
    "    'metric': 'binary_logloss',  # Logarithmic loss for binary classification\n",
    "    'boosting_type': 'gbdt',  # Gradient boosting decision tree\n",
    "    'num_leaves': 31,  # Maximum number of leaves in each tree\n",
    "    'learning_rate': 0.05,  # Step size shrinkage\n",
    "    'feature_fraction': 0.75,  # Fraction of features to be used in each iteration\n",
    "    'bagging_fraction': 0.90,  # Fraction of data to be randomly sampled for training\n",
    "    'bagging_freq': 5,  # Frequency for bagging\n",
    "    'verbose': 0  # Verbosity level,    \n",
    "}\n",
    "\n",
    "num_boost_round = 210  # Number of boosting rounds\n",
    "\n",
    "# Train the LightGBM model on the training dataset\n",
    "model = lgb.train(params, train_dataset, num_boost_round=num_boost_round)\n",
    "\n",
    "# Prepare the other dataset for predictions\n",
    "X_test = test_data  # Preprocess your other dataset as needed\n",
    "\n",
    "# Make predictions using the trained model\n",
    "record_ids = X[\"RecordID\"]\n",
    "probs = lightgbm_model.predict(X_test)\n",
    "\n",
    "result = pd.DataFrame({'RecordID': record_ids, 'hospital_death': probs})\n",
    "    \n",
    "# Save the results to a CSV file\n",
    "result.to_csv(\"results54\", index=False, header=[\"RecordID\", \"hospital_death\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "robust_scale_df = robust_scale(test_df)\n",
    "df_test_imputed = knn_impute_numerical_columns(robust_scale_df, n_neighbors=100)\n",
    "df_test_onehot = pd.get_dummies(df_test_imputed)\n",
    "X_test = df_test_onehot[selected_features]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lightgbm_model.predict(X_test)\n",
    "y_pred_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_ids = test_df[\"RecordID\"]\n",
    "result = pd.DataFrame({'RecordID': record_ids, 'hospital_death': probs})\n",
    "    \n",
    "# Save the results to a CSV file\n",
    "result.to_csv(\"results54.csv\", index=False, header=[\"RecordID\", \"hospital_death\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
